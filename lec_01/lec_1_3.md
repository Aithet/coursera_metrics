Лекция 1


* Два вопроса

* Данные
- временные ряды
- перекрестная выборки
- панельные данные
- пример таблички

* всегда изображайте данные

* простая модель

* метод наименьших квадратов

* мнк к нашим данным: быстро ответ и проинтерпретировать

* мнк-руками (для y=bx+e) --- убрать в упражнения (!)

* терминология

* иллюстрация понятий на 2d графике (чудо доска)
- истинные бета не видны!
мы их не знаем и никогда не узнаем

* 2 случая:
- третий --- в упражнения
- табличка с данными
- 2 модели
- вывод общей формулы
- применение к табличке

* вывод.

* Чудо-Доска много объясняющих переменных

* вывод FOC в скалярном виде

# Абсолютный ликбез по линейной алгебре
* длина вектора
* квадрат длины вектора
* скалярное произведение
(само по себе трудно интерпретировать, позволяет найти косинус)
* условие перпендикулярности

* модель в векторной форме: 
\hat{y} выражается через столбцы матрицы регрессоров

* FOC: вектор остатков перпендикулярен регрессорам

* картинка 1. интерпретация регрессии на свободный член
теорема Пифагора

* картинка 2. интерпретация множественной регрессии

* RSS, ESS, TSS
определение

Теорема: если в регрессию включен свободный член

* геометрическое доказательство

* теорема о вершине ёлки (теорема о 3-х перпендикулярах)

* Коэффициент детерминации

Теорема 2: равен квадрату выборочной корреляции s.corr(y,z)

* граф. доказательство

* ЛИНАЛ: вывод общей формулы для бет

* Итоги. Метод наименьших квадратов позволяет оценивать неизвестные коэффиценты
* должно остаться больше вопросов, чем ответов :)

R:

* R как калькулятор
- присваивание = и <- 
- заглавные и строчные
- + в строке
- tab
- NA, NaN, Inf
- вектора, номер сбоку

* скрипт
- векторные операции, mean(v) с NA и без
- 
- табличка
- адресация таблички
- список (чердак со всяким хламом)
- адресация списка
- сохранение/чтение скрипта: кодировка

* установка и подключение пакетов
ggplot2, GGally, dplyr, sophisthse, broom


* посмотри на данные
- на примере машинок
glimpse()
tail()
head()
describe()
str()
nrow()
ncol()

mean()
sd()
table()
cor()


* простые действия со встроенными наборами данных
data()
- mutate
mutate(dist=0.3*dist,speed=1.67*speed)
- filter
- select


* графики для количественных переменных:
- гистограмма
- диаграмма рассеяния
- много диаграмм рассеяния

* график --- для себя --- для публикации (или в лекцию?)

* линейная регрессия в R (cars)
model <- 
model.matrix(model)
coef(model)
deviance(model)
residuals(model)
fitted(model)
TSS (by hand)
R^2 (by hand)
(через report <- summary(model))
report$r.squared

* прогнозируем
nd <- 

* с набором данных swiss

* справка по R
- google/rseek
- stats.stackexchange
- stackoverflow
- help() 
- в скобках в каком пакете живет функция




Лекция 2

* условное м.о. и условная дисперсия

* концептуально
выбираю случайный день в году
y --- температура
x --- месяц
E(y) --- число 
E(y|x) --- случайная величина


* E(w|z) 
случайная величина f(z) наиболее похожая на случайную величину w 

случайная величина f(z) называется условным м. ожиданием величны w при фиксированной z, 
если E[(w-f(z))^2] принимает минимальное возможное выражение.

* Теорема. Если z принимает несколько значений 

* несколько примеров подсчета

* Свойства E(y|x), Var(y|x)

* Предпосылки

* Модель парной регрессии

* Найдите Var(\hb_2|X), Cov(\hb_1,\hb_2 |X), Var(\hb_1|X)

* Теорема (без доказательства):
Var(\hb_j|X)=\sigma^2/RSS_j

* Ковариационная матрица Var(\hat{\beta}|X)



* Запись предпосылок с помощью ковариационной матрицы 
- единичная матрица

* Способ оценить неизвестную \sigma^2
- без док-ва
Если...
и \hat{\sigma}^2 = RSS/(n-k) то
1.
2. норм
3. n \to \infty

* способ оценить ковариационную матрицу

\widehad{Var}(\hb_2|X) =

коротко: se^2(\hb_2)

стало быть, se^2(\hb_2)=\hat{\sigma}^2/RSS_2

* Если выполнены предпосылки

и норм то t_{n-k}
и n\to\inf то N(0;1)

* проверка гипотезы о значимости коэффициента 
- выбираете уровень значимости альфа
- формулируете H_0

- вывод: H0 отвергается/H0 не отвергается

* Чудо-доска
- уравнение регрессии
- ковариационная матрица
- проверьте гипотезу
- постройте доверительный интервал

* стандартные ошибки часто выписывают под коэффициентами

* прогнозы

* два типа доверительных интервалов для прогноза 
- доверительный интервал для среднего
- предиктивный интервал для конкретного будущего y

* Чудо-доска
- строим доверительный интервал
- строим предиктивный интервал



* ЛИНАЛ оступление для знающих линейную алгебру
- матричные свойства E(y)
- матричные свойства E(y|x)

* ЛИНАЛ: вывод Var(\hat{\beta}|X)

R: 
* функци плотности --- графики
- R вместо статистических таблиц


* достаем ковариационную матрицу из уже оцененной модели

* интерпретируем стандартную табличку

* прогнозируем и строим предиктивные интервалы

* загрузка внешних данных
- csv
- csv в России больше, чем csv (!)
- Excel/spss/stata

* загрузка данных RLMS

- чистим RLMS
- сверка типов данных
- замена NA




Лекция 3.

* Снова все предпосылки

* Три группы свойств

* Гипотеза о нескольких линейных ограничениях
- ограниченная и неограниченная модель


* Гипотеза о значимости регрессии в целом

* дамми-переменные

- на примере про квартиры в Москве
* модель 1 (всё одинаково для двух групп)
* модель 2 (отличаются свободные члены)
* модель 3 (отличаются и свободные члены и наклоны)

- три пары Restricted-Unrestricted

* последствия лишних включенных переменных

* последствия пропущенных переменных

* RESET-тест


# R

* Больше графиков
- рассеяния и очень много наблюдений
- количественная-качественная
- много качественных


* маленькое исследование в R

* waldtest()

* RESET-тест













* Презентация помощников :)
* метод наименьших квадратов: 
- рост-вес, задача про слитки
- множественная регрессия
- модель CAPM
- сразу множественная регрессия
- RSS, R^2, TSS, ESS, остатки (ошибки прогнозов)
* введение в R
- введение в R-studio (картинка в картинке)
- в R есть встроенные наборы данных
- установка пакетов и загрузка пакетов
- чтение данных из разных источников: csv (российские нюансы)
- описательные статистики
- основные ggplot2 графики: гистограмма, рассеяния (+hexbin), # facet, 
- парная регрессия


quiz: + неоцениваемый data.camp
нестатистич мнк (посчитать R2, остатки, можем ли мы посчитать эпсилон2 по реальным данным)
какая команда посчитает среднее у вектора z: average(z), mean(z), 
неоцениваемый data.camp (чуть больше)
простая работа со встроенным набором данных (посчитайте среднюю цену бриллиантов)




Лекция 2
* Проекция (картинка): условия первого порядка скалярно и матрично
* вывод дисперсии \hb_2, \hb_1 и ковариации \hb_1 и \hb_2
* объяснение понятия ковариационная матрица \hb
* вывод дисперсии \hb для тех кто знает линейную алгебру
* напоминание про условное математическое ожидание
* проверка гипотез, доверительные интервалы для коэффициентов (t-распределение)
* расшифровка стандартной таблички R
* p-value
* точечный прогноз
* R вместо статистических таблиц

quiz: (c возможностью запустить data.camp)
теоретически по табличке проверьте гипотезы
по встроенному набору данных оцените проверьте спрогнозируйте


Лекция 3
Теорема Гаусса-Маркова
* версия с фиксированными переменными (убрать почти полностью)
* версия со стохастическими регрессорами (сразу)
проверка гипотезы об одном линейном ограничении
проверка гипотезы о значимости регрессии в целом
проверка гипотез о линенйых ограничениях
дамми переменные - возврат к задаче про слитки
ограниченная / неограниченная модель тестирование
* два типа доверительных интервала для прогнозов
- прогнозирование в R
- деление выборки на две части
* загрузка данных из внешних источников

посчитать --- среднее доход по мужчинам
построить регрессию конкртено y на x2, x3 и:
(для себя построить график (не оцениваниется))
найти r2
построить доверительные интервал для beta2
спрогнозоировть y у мужчины c x2=..., x3=... и поместить в переменную 







