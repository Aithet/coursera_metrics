\documentclass[ignorenonframetext,]{beamer}
\usetheme{CambridgeUS}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\usepackage{lmodern}
\ifxetex
  \usepackage{fontspec,xltxtra,xunicode}
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\else
  \ifluatex
    \usepackage{fontspec}
    \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
    \newcommand{\euro}{€}
  \else
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
      \fi
\fi
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

% Comment these out if you don't want a slide with just the
% part/section/subsection/subsubsection title:
\AtBeginPart{
  \let\insertpartnumber\relax
  \let\partname\relax
  \frame{\partpage}
}
\AtBeginSection{
  \let\insertsectionnumber\relax
  \let\sectionname\relax
  \frame{\sectionpage}
}
\AtBeginSubsection{
  \let\insertsubsectionnumber\relax
  \let\subsectionname\relax
  \frame{\subsectionpage}
}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
\usepackage[russian]{babel}

\title{Эконометрика. Лекция 2}

\begin{document}
\frame{\titlepage}

\begin{frame}{Статистические свойства оценок коэффициентов}

\begin{itemize}
\item
  сформулируем стандартные предпосылки
\item
  строить доверительные интервалы для коэффициентов
\item
  проверять гипотезы о коэффициентах
\end{itemize}

\end{frame}

\begin{frame}{Условное математическое ожидание}

$r$ --- одна случайная величина

$s$ --- одна случайная величина

\end{frame}

\begin{frame}{Условное математическое ожидание. Неформально}

$E(s|r)$ --- это такая функция от случайной величины $r$, которая
наиболее похожа на случайную величину $s$

\end{frame}

\begin{frame}{Условное математическое ожидание. Формально}

$E(s|r)$ --- это случайная величина $\tilde{s}$:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  представимая в виде $\tilde{s}=f(r)$
\item
  $E(\tilde{s})=E(s)$
\item
  $Cov(s-\tilde{s},g(r))=0$ для любой $g(r)$.
\end{enumerate}

Или: $Cov(s,g(r))=Cov(\tilde{s},g(r))$

\end{frame}

\begin{frame}{На практике}

Теорема: Если величина $r$ дискретна и принимает значения $a$, $b$ или
$c$, то

\[
E(s|r)=\begin{cases}
E(s|r=a), \text{ если } r=a \\
E(s|r=b), \text{ если } r=b \\
E(s|r=c), \text{ если } r=c 
\end{cases}
\]

\end{frame}

\begin{frame}{Пример расчета чудо-доска}

\end{frame}

\begin{frame}{Если величины непрерывны и есть совместная функция
плотности}

Теорема: Если пара величин $x$, $y$ имеет функцию плотности $f(r,s)$, то
\[
E(s|r)=\int_{-\infty}^{\infty} s \cdot f(s|r) dx
\]

где $f(s|r)=f(r,s)/f(r)$ --- условная функция плотности

\end{frame}

\begin{frame}{Свойства условного ожидания}

Пусть $a$, $b$ --- константы, $s$, $r$ --- случайные величины.

Идея: свойства $E(s|r)$ аналогичны свойствам $E(s)$, если считать $r$ и
любую функцию $h(r)$ константой.

\end{frame}

\begin{frame}{Список свойств}

\begin{itemize}
\item
  $E(E(s|r))=E(s)$
\item
  $E(as+b|r)=aE(s|r)+b$
\item
  $E(h(r)|r)=h(r)$
\item
  $E(h(r)s|r)=h(r)E(s|r)$
\end{itemize}

\end{frame}

\begin{frame}{Условная дисперсия и ковариация}

Обычная дисперсия: $Var(s)=E(s^2)-(E(s))^2$

Условная дисперсия. $Var(s|r)=E(s^2|r)-(E(s|r))^2$

Обычная ковариация: $Cov(s_1,s_2)=E(s_1 s_2)-E(s_1)E(s_2)$

Условная ковариация: $Cov(s_1,s_2|r)=E(s_1 s_2|r)-E(s_1|r)E(s_2|r)$

\end{frame}

\begin{frame}{чудо-доска. пример расчета условной дисперсии}

\end{frame}

\begin{frame}{Свойства условной дисперсии}

Пусть $a$, $b$ --- константы, $s$, $r$ --- случайные величины.

Идея: свойства $Var(s|r)$ аналогичны свойствам $Var(s)$, если считать
$r$ и любую функцию $h(r)$ константой.

\end{frame}

\begin{frame}{Свойства}

$Var(as+b|r)=a^2Var(s|r)$

$Var(s+h(r)|r)=Var(s|r)$

$Var(h(r)s|r)=h^2(r)Var(s|r)$

$Var(s)=Var(E(s|r))+E(Var(s|r))$

\end{frame}

\begin{frame}{Геометрическая интерпретация. Чудо-доска.}

\end{frame}

\begin{frame}{Мораль геометрической интерпретации:}

Если считать, что $Cov(r,s)$ --- скалярное произведение, то

\begin{itemize}
\item
  квадрат длины случайной величины $r$, $Var(r)$
\item
  косинус угла между случайными величинами, $Corr(s,r)$
\end{itemize}

Верны ``школьные'' теоремы: теорема Пифагора, Фалеса, etc

\end{frame}

\begin{frame}{Предпосылки на ошибки}

\begin{itemize}
\item
  $E(\varepsilon_i |X)=0$
\item
  $E(\varepsilon_i^2|X)=\sigma^2$ или $Var(\varepsilon_i|X)=\sigma^2$
\item
  $E(\varepsilon_i \varepsilon_j|X)=0$ или
  $Cov(\varepsilon_i,\varepsilon_j|X)=0$
\end{itemize}

\end{frame}

\begin{frame}{ковариационная матриц}

Ковариационная матрица вектора $\varepsilon$:

\[
Var(\varepsilon)=\begin{pmatrix}
Var(\varepsilon_1) & Cov(\varepsilon_1,\varepsilon_2) & Cov(\varepsilon_1,\varepsilon_3) & \ldots \\
Cov(\varepsilon_2,\varepsilon_1) & Var(\varepsilon_2) &  Cov(\varepsilon_2,\varepsilon_3) & \ldots \\
Cov(\varepsilon_3,\varepsilon_1) & Cov(\varepsilon_3,\varepsilon_2) & Var(\varepsilon_3) &   \ldots \\
\vdots & & 
\end{pmatrix}
\]

\end{frame}

\begin{frame}{запись предпосылок с помощью ковариационной матрицы}

\[
Var(\varepsilon|X) = \begin{pmatrix}
\sigma^2 & 0 & 0 & \ldots \\
0 & \sigma^2 & 0 & \ldots \\
0 & 0 & \sigma^2 & \ldots \\
\vdots & \vdots &\vdots  & \\
\end{pmatrix}
= \sigma^2 \begin{pmatrix}
1 & 0 & 0 & \ldots \\
0 & 1 & 0 & \ldots \\
0 & 0 & 1 & \ldots \\
\vdots & \vdots &  \vdots & \\
\end{pmatrix}=\sigma^2 \cdot I_{n\times n}
\]

\end{frame}

\begin{frame}{Дисперсия и ковариация оценок коэффициентов}

Предпосылки:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $Var(\varepsilon|X)=\sigma^2 \cdot I_{n\times n}$
\item
  $Var(\varepsilon_i|X)=\sigma^2$
\item
  $Cov(\varepsilon_i,\varepsilon_j|X)=0$
\item
  $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i +\varepsilon_i$
\end{itemize}

Позволяют посчитать $Var(\hat{\beta}_j)$,
$Cov(\hat{\beta}_j,\hat{\beta}_l)$

\end{frame}

\begin{frame}{Пример вычислений в парной регрессии (в регрессии на
константу)}

чудо-доска.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Найдите $Var(\hat{\beta}_2|X)$, $Cov(\hat{\beta}_1,\hat{\beta}_2 |X)$,
  $Var(\hat{\beta}_1|X)$
\end{itemize}

\end{frame}

\begin{frame}{Итого в парной регрессии:}

\begin{itemize}
\item
  $Var(\hat{\beta}_2|X)=\frac{\sigma^2}{\sum (x_i-\bar{x})^2}$
\item
  $Cov(\hat{\beta}_1,\hat{\beta}_2 |X)=\frac{-\bar{x}\sigma^2}{\sum (x_i-\bar{x})^2}$
\item
  $Var(\hat{\beta}_1|X)=\frac{\sigma^2 \sum x_i^2}{n\sum (x_i-\bar{x})^2}$
\end{itemize}

\end{frame}

\begin{frame}{Вопрос:}

\begin{itemize}
\item
  Зачем придумали эту условную дисперсию, если все свойства аналогичны
  обычной дисперсии?
\item
  А вот как раз и придумали, чтобы аналогичны всё было :)
\end{itemize}

\end{frame}

\begin{frame}{Теорема (без доказательства):}

\[
Var(\hat{\beta}_j| X)=\sigma^2/RSS_j
\] $RSS_j$ --- сумма квадратов остатков в регрессии $j$-ой объясняющей
переменной на остальные объясняющие переменные

\end{frame}

\begin{frame}{ЛИНАЛ: прелюдия к доказательству}

ЛИНАЛ: $Var(\hat{\beta}|X)=\sigma^2 (X'X)^{-1}$

Свойство: $Var(Ay)=AVar(y)A'$

Напомним, что $(AB)'=B'A'$ и $(A^{-1})'=(A')^{-1}$ поэтому:

\begin{itemize}
\item
  $(X'X)'=X'X''=X'X$
\item
  $((X'X)^{-1})'=(X'X)^{-1}$
\end{itemize}

\end{frame}

\begin{frame}{ЛИНАЛ: чудо-доска}

Если оценки МНК существуют и единственны,
$Var(\varepsilon|X)=\sigma^2 I_{n\times n}$

то $Var(\hat{\beta}|X)=\sigma^2 (X'X)^{-1}$

Доказательство

\end{frame}

\begin{frame}{Как оценить $\sigma^2$?}

Константа $\sigma^2$ неизвестна.

Случайная величина $\hat{\sigma}^2=\frac{RSS}{n-k}$ --- замечательная
оценка для $\sigma^2$.

\end{frame}

\begin{frame}{Оценка ковариационной матрицы}

\begin{itemize}
\item
  $Var(\hat{\beta}_j | X)=\sigma^2 \cdot f(X)$
\item
  $\widehat{Var}(\hat{\beta}_j | X)=\hat{\sigma}^2 \cdot f(X)$
\end{itemize}

а именно: $\widehat{Var}(\hat{\beta}_j| X)=\hat{\sigma}^2/RSS_j$

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $se(\hat{\beta}_j)=\sqrt{(\hat{\beta}_j | X)}$
\end{itemize}

Например, в модели $y_i=\beta_1 + \beta_2 x_i + \varepsilon_i$:
$se(\hat{\beta}_2)=\sqrt{\frac{\hat{\sigma}^2}{\sum (x_i-\bar{x})^2}}$

\end{frame}

\begin{frame}{оценка ковариационной матрицы}

\[
\widehat{Var}(\hat{\beta}|X)=\begin{pmatrix}
\widehat{Var}(\hat{\beta}_1|X) & \widehat{Cov}(\hat{\beta}_1,\hat{\beta}_2|X) & \widehat{Cov}(\hat{\beta}_1,\hat{\beta}_3|X) & \ldots \\
\widehat{Cov}(\hat{\beta}_2,\hat{\beta}_1|X) & \widehat{Var}(\hat{\beta}_2|X) &  \widehat{Cov}(\hat{\beta}_2,\hat{\beta}_3|X) & \ldots \\
\widehat{Cov}(\hat{\beta}_3,\hat{\beta}_1|X) & \widehat{Cov}(\hat{\beta}_3,\hat{\beta}_2|X) & \widehat{Var}(\hat{\beta}_3|X) &   \ldots \\
\vdots & & 
\end{pmatrix}
\]

\begin{itemize}
\item
  ЛИНАЛ:
  $\widehat{Var}(\hat{\beta} | X)=\hat{\sigma}^2 \cdot (X'X)^{-1}$
\item
  В R: \texttt{vcov(model)}
\end{itemize}

\end{frame}

\begin{frame}{БСХС - Большой Список Хороших Свойств}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Базовые:
\end{itemize}

верны даже на малых выборках без предположения о нормальности
$\varepsilon_i$

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Асимптотические:
\end{itemize}

верны на больших выборках даже без предположения о нормальности
$\varepsilon_i$

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  При нормальности:
\end{itemize}

верны при нормальности $\varepsilon_i$ даже на малых выборках

\end{frame}

\begin{frame}{БСХС --- предпосылки}

Если:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Истинная зависимость имеет вид
  $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i+\varepsilon_i$
\end{enumerate}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  В матричном виде: $y=X\beta + \varepsilon$
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\itemsep1pt\parskip0pt\parsep0pt
\item
  С помощью МНК оценивается регрессия $y$ на константу, $x_i$, $z_i$
\end{enumerate}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  В матричном виде: $\hat{\beta}=(X'X)^{-1}X'y$
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Наблюдений больше, чем оцениваемых коэффициентов $\beta$: $n>k$
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предположения на $\varepsilon_i$:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Строгая экзогенность: $E(\varepsilon_i | \text{ все регрессоры } )=0$
\end{enumerate}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  В матричном виде: $E(\varepsilon_i | X)=0$
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Условная гомоскедастичность:
  $E(\varepsilon_i^2 | \text{ все регрессоры })=\sigma^2$
\end{enumerate}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  В матричном виде: $E(\varepsilon_i^2 | X)=\sigma^2$
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $Cov(\varepsilon_i,\varepsilon_j | X)=0$ при $i \neq j$
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предпосылки на регрессоры}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\itemsep1pt\parskip0pt\parsep0pt
\item
  векторы отдельных наблюдений $(x_i,z_i,y_i)$ --- независимы и
  одинаково распределены
\item
  с вероятностью 1 среди регрессоров нет линейно зависимых
\end{enumerate}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Синонимы в матричном виде: $rank(X)=k$ или $det(X'X)\neq 0$ или
  $(X'X)^{-1}$ существует
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- базовые свойства (т. Гаусса-Маркова)}

\begin{itemize}
\item
  Оценки $\hat{\beta}_j$ линейны по $y_i$:
  $\hat{\beta_j}=c_1 y_1 + \ldots + c_n y_n$
\item
  Оценки несмещены: $E(\hat{\beta}_j |X )=\beta_j$, и в частности
  $E(\hat{\beta}_j)=\beta_j$
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- базовые свойства (т. Гаусса-Маркова)}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Оценки эффективны среди линейных и несмещенных
\end{itemize}

Для любой линейной по $y_i$ и несмещенной альтернативной оценки
$\hat{\beta}^{alt}$:

$Var(\hat{\beta}_j^{alt} | X)\geq Var(\hat{\beta}_j | X)$ и
$Var(\hat{\beta}_j^{alt} )\geq Var(\hat{\beta}_j )$

\end{frame}

\begin{frame}{БСХС --- базовые свойства}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Ковариационная матрица: $Var(\hat{\beta} | X )=\sigma^2 (X'X)^{-1}$
\end{itemize}

Диспрерсии: $Var(\hat{\beta}_j| X)=\sigma^2/RSS_j$

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $Cov(\hat{\beta}_j,\hat{\varepsilon}_i | X)=0$
\item
  $E(\hat{\sigma}^2 |X ) = \sigma^2$, и $E(\hat{\sigma}^2 ) = \sigma^2$
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- асимптотические свойства}

При $n\to \infty$:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $\hat{\beta}_j \to \beta_j$ по вероятности
\item
  $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)$ по
  распределению
\item
  $\hat{\sigma}^2 \to \sigma^2 $ по вероятности
\end{itemize}

$\hat{\sigma}^2=\frac{RSS}{n-k}$

\end{frame}

\begin{frame}{БСХС --- при нормальности}

Если дополнительно известно, что $\varepsilon_i \sim N(0, \sigma^2)$:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Оценки эффективны среди несмещенных
\item
  $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}|X \sim t_{n-k}$,
  $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}\sim t_{n-k}$
\item
  $RSS/\sigma^2 |X \sim \chi^2_{n-k}$, $RSS/\sigma^2 \sim \chi^2_{n-k}$
\end{itemize}

\end{frame}

\begin{frame}{Доверительные интервалы для коэффициентов}

Возможно строить в двух подходах:

\begin{itemize}
\item
  Асимптотически:
  $t=\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)$
\item
  При нормальности:
  $t=\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \sim t_{n-k}$
\end{itemize}

Примерный 95\%-ый интервал:

$[\hat{\beta}_j-2se(\hat{\beta}_j);\hat{\beta}_j+2se(\hat{\beta}_j) ] $

\end{frame}

\begin{frame}{Описание любого теста:}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  предпосылки теста (например, асимптотический или точный)
\item
  проверяемая $H_0$ против $H_a$
\item
  формула для вычисления статистики
\item
  закон распределения статистики при верной $H_0$
\end{itemize}

\end{frame}

\begin{frame}{Последовательность действий}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  выбираем уровень значимости $\alpha$,
  $\alpha=P(H_0 \text{ отвергнута }| H_0 \text{ верна })$
\item
  находим наблюдаемое значение некоторой статистики
\item
  находим критическое значение статистики (можно посчитать P-значение)
\item
  сравниваем критическое и наблюдаемое (можно сравнить P-значение и
  $\alpha$)
\item
  вывод: ``$H0$ отвергается'' или ``$H0$ не отвергается''
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{Чудо-доска}

Дано:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  уравнение регрессии
\item
  ковариационная матрица
\item
  оценка $\hat{\sigma}^2$
\end{itemize}

(Intercept) 59.86392 3.98754 15.013 \textless{}2e-16 **\emph{
Agriculture 0.10953 0.07848 1.396 0.1698\\Catholic 0.11496 0.04274 2.690
0.0101 }

\begin{verbatim}
         (Intercept)  Agriculture     Catholic
\end{verbatim}

(Intercept) 15.900471817 -0.256680712 -0.006998292 Agriculture
-0.256680712 0.006159437 -0.001345371 Catholic -0.006998292 -0.001345371
0.001826622

Residual standard error: 11.07

Надо:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  проверьте гипотезу
\item
  постройте доверительный интервал
\item
  постройте доверительный интервал для сигма
\end{itemize}

\end{frame}

\begin{frame}{стандартные ошибки часто выписывают под коэффициентами}

$\widehat{Fertility}_i=\underset{(3.98)}{59.8} + \underset{(0.078)}{0.109} Agriculture_i + \underset{(0.042)}{0.115} Catholic_i$

\end{frame}

\begin{frame}[fragile]{стандартная табличка в любом пакете + чудо-доска}

Вывели на экран, рядом рассказали на примере одного коэффициента с
графиком!

\begin{verbatim}
        Estimate Std. Error t value Pr(>|t|)   
        
\end{verbatim}

(Intercept) 59.86392 3.98754 15.013 \textless{}2e-16 ***

Agriculture 0.10953 0.07848 1.396 0.1698

Catholic 0.11496 0.04274 2.690 0.0101 *

\end{frame}

\begin{frame}{Плохое название}

Проверка значимости --- на самом деле проверка незначимости:

\begin{itemize}
\item
  ``Мы проверили значимость коэффициента при доходе''
\item
  Мы проверили $H_0: \beta_{inc}=0$.
\end{itemize}

\end{frame}

\begin{frame}{H0 не отвергается}

\begin{itemize}
\item
  недостаточно данных чтобы отвергнуть H0
\item
  имеющиеся данные не противоречат H0
\end{itemize}

(много еще чему не противоречат)

\end{frame}

\begin{frame}{Значимость и существенность}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Коэффициент может быть значимым и совершенно несущественным
\end{itemize}

На огромных выборках --- все коэффиценты значимы

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Коэффициент может быть существенным но не значимым
\end{itemize}

\end{frame}

\begin{frame}{Стандартизированные коэффициенты}

Существенность --- можно придать разный математический смысл

Например:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  стандартизировать переменные:
\end{itemize}

$y^{st}_i:= \frac{y_i-\bar{y}}{sd(y)}$,
$x^{st}_i:= \frac{x_i-\bar{x}}{sd(x)}$,
$z^{st}_i:= \frac{z_i-\bar{z}}{sd(z)}$

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  переоценить модель:
\end{itemize}

$y^{st}_i=\beta_1^{st}+\beta_2^{st}x_i^{st}+\beta_3^{st}z_i^{st}+\varepsilon_i^{st}$

\end{frame}

\begin{frame}{Проблема множественных сравнений}

\begin{itemize}
\item
  Исследователь хочет проверить гипотезу о том, что $\beta_{42}=0$. Ok.
\item
  Исследователь хочет выяснить какие регрессоры из 100 значимы. Нужна
  поправка.
\end{itemize}

\end{frame}

\begin{frame}{Проверка гипотезы об одном ограничении}

Хотим проверить гипотезу о $\beta_2-\beta_3$.

Статистика
$t=\frac{\hat{\beta}_2-\hat{\beta}_3-(\beta_2-\beta_3)}{se(\hat{\beta}_2-\hat{\beta}_3)}$
распределена

\begin{itemize}
\item
  асимпотитически $N(0,1)$
\item
  при нормальности $t_{n-k}$
\end{itemize}

\end{frame}

\begin{frame}{Переформулировка модели}

Хотим проверить гипотезу о $\beta_2-\beta_3$.

Всегда можно переформулировать модель так, что $\beta_2-\beta_3$ станет
новым коэффициентом $\beta_2'=\beta_2-\beta_3$.

\end{frame}

\begin{frame}{Пример у чудо-доски}

\begin{itemize}
\item
  способ через ковариационную матрицу
\item
  способ через переформулировку модели
\end{itemize}

\end{frame}

\begin{frame}{Мораль:}

В этой лекции мы научились:

\begin{itemize}
\item
  строить доверительные интервалы
\item
  проверять гипотезы об отдельном коэффициенте
\item
  сформулировали все стандартные предпосылки
\end{itemize}

В следующей:

\begin{itemize}
\item
  более сложные гипотезы
\item
  прогнозирование
\end{itemize}

\end{frame}

\end{document}
