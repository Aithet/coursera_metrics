\documentclass[russian,ignorenonframetext,]{beamer}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
\usetheme{Madrid}
\usecolortheme{whale}
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[shorthands=off,main=russian]{babel}
\else
  \usepackage{polyglossia}
  \setmainlanguage[]{}
\fi
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}

% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom

\AtBeginPart{
  \let\insertpartnumber\relax
  \let\partname\relax
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \let\insertsectionnumber\relax
    \let\sectionname\relax
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \let\insertsubsectionnumber\relax
  \let\subsectionname\relax
  \frame{\subsectionpage}
}

\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
\author[Эконометрика. Лекция 3]{Эконометрика. Лекция 3}
\newcommand{\e}{\varepsilon}
\newcommand{\hy}{\hat{y}}
\newcommand{\hb}{\hat{\beta}}
\usepackage{lmodern}
\usepackage{tikz}

\title{Прогнозы. Сравнение моделей}
\date{}

\begin{document}
\frame{\titlepage}

\begin{frame}{Лекция 3}

\begin{itemize}
\item
  Прогнозирование
\item
  Выбор ``наилучшей'' модели
\end{itemize}

\end{frame}

\begin{frame}{Прогнозирование}

Модель: \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)

Точечный прогноз:
\(\hat{y}_i = \hat{\beta}_1 +\hat{\beta}_2 x_i + \hat{\beta}_3 z_i\)

\end{frame}

\begin{frame}{Интервальное прогнозирование}

Что мы прогнозируем?

\begin{itemize}
\tightlist
\item
  Средний \(y_i\) при данных регрессорах, \(E(y_i | x_i, z_i)\):
\end{itemize}

\(E(y_i | x_i, z_i)=\beta_1 + \beta_2 x_i + \beta_3 z_i\)

\begin{itemize}
\tightlist
\item
  Конкретный \(y_i\) при данных регрессорах:
\end{itemize}

\(y_i= \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)

Возникает две разных ошибки прогноза!

\end{frame}

\begin{frame}{Ошибка прогнозирования среднего}

\begin{itemize}
\item
  условное среднее, \(E(y_i | X)\)
\item
  ошибка прогноза условного среднего, \(\hat{y}_i - E(y_i | X)\)
\item
  дисперсия ошибки прогноза:
\end{itemize}

\[
Var(\hy_i - E(y_i | X)  | X )=Var(\hat{y}_i | X)  =Var(\hat{\beta}_1 +\hat{\beta}_2 x_i + \hat{\beta}_3 z_i | X)
\]

\end{frame}

\begin{frame}{Ошибка прогноза конкретного значения}

\begin{itemize}
\item
  конкретное наблюдение, \(y_i\)
\item
  ошибка прогноза, \(\hy_i - y_i\)
\item
  дисперсия ошибки прогноза:

  \begin{multline} \nonumber
  Var(\hat{y}_i - y_i | X)=Var(\hat{y}_i - E(y_i | X) - \varepsilon_i | X) = Var(\hat{y}_i - \varepsilon_i | X) = \\
  Var(\hat{y}_i|X) + Var( \varepsilon_i | X) = Var(\hat{\beta}_1 +\hat{\beta}_2 x_i + \hat{\beta}_3 z_i | X) + Var(\epsilon_i | X)
  \end{multline}
\end{itemize}

\end{frame}

\begin{frame}{Оценка дисперсии}

\begin{itemize}
\item
  \(Var(\hat{y}_i |X )\), \(Var(\e_i | X)\) неизвестны, зависят от
  \(\sigma^2\)
\item
  \(\widehat{Var}(\hat{y}_i |X )\), \(\widehat{Var}(\e_i | X)\) известны
\item
  Используем стандартные ошибки:
  \(se(\hat{y}_i) = \sqrt{\widehat{Var}(\hat{y}_i |X )}\)
\end{itemize}

\end{frame}

\begin{frame}{Доверительный интервал для среднего значения}

\begin{itemize}
\item
  Асимптотический:
  \(\frac{\hat{y}_i - E(y_i | X)}{se(\hat{y}_i)} \to N(0,1)\) \[
  E(y_i | X) \in [\hat{y}_i - z_{cr} se(\hat{y}_i);\hat{y}_i + z_{cr} se(\hat{y}_i) ]
  \]
\item
  При предположении о нормальности:
  \(\frac{\hat{y}_i - E(y_i | X)}{se(\hat{y}_i)} \sim t_{n-k}\)
\end{itemize}

\[
E(y_i | X) \in [\hat{y}_i - t_{cr} se(\hat{y}_i);\hat{y}_i + t_{cr} se(\hat{y}_i) ]
\]

\end{frame}

\begin{frame}{Предиктивный интервал для конкретного значения}

\begin{itemize}
\item
  Асимптотический:
  \(\frac{\hat{y}_i - y_i }{se(\hat{y}_i-\varepsilon_i)} \to N(0,1)\) \[
  y_i  \in [\hat{y}_i - z_{cr} se(\hat{y}_i-\varepsilon_i);\hat{y}_i + z_{cr} se(\hat{y}_i-\varepsilon_i) ]
  \]
\item
  При предположении о нормальности:
  \(\frac{\hat{y}_i - y_i }{se(\hat{y}_i-\varepsilon_i)} \sim t_{n-k}\)
\end{itemize}

\[
y_i  \in [\hat{y}_i - t_{cr} se(\hat{y}_i-\varepsilon_i);\hat{y}_i + t_{cr} se(\hat{y}_i-\varepsilon_i) ]
\]

\end{frame}

\begin{frame}[fragile]{Пример вычислений {[}у доски{]}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Coefficients:}
\StringTok{            }\NormalTok{Estimate Std. Error t value }\KeywordTok{Pr}\NormalTok{(>}\ErrorTok{|}\NormalTok{t|)    }
\NormalTok{(Intercept)  }\FloatTok{8.53539}    \FloatTok{0.05183}  \FloatTok{164.68}   \NormalTok{<}\FloatTok{2e-16} \NormalTok{**}\ErrorTok{*}
\KeywordTok{log}\NormalTok{(carat)   }\FloatTok{1.74685}    \FloatTok{0.07505}   \FloatTok{23.27}   \NormalTok{<}\FloatTok{2e-16} \NormalTok{**}\ErrorTok{*}
\NormalTok{---}
\NormalTok{Signif. codes:}\StringTok{  }\DecValTok{0} \NormalTok{‘**}\ErrorTok{*}\NormalTok{’ }\FloatTok{0.001} \NormalTok{‘**’ }\FloatTok{0.01} \NormalTok{‘*’ }\FloatTok{0.05} \NormalTok{‘.’ }\FloatTok{0.1} \NormalTok{‘ ’ }\DecValTok{1}

\NormalTok{Residual standard error:}\StringTok{ }\FloatTok{0.2771} \NormalTok{on }\DecValTok{38} \NormalTok{degrees of freedom}

\KeywordTok{vcov}\NormalTok{(mod)}
            \NormalTok{(Intercept)  }\KeywordTok{log}\NormalTok{(carat)}
\NormalTok{(Intercept) }\FloatTok{0.002686470} \FloatTok{0.002078281}
\KeywordTok{log}\NormalTok{(carat)  }\FloatTok{0.002078281} \FloatTok{0.005632675}
\end{Highlighting}
\end{Shaded}

\end{frame}

\begin{frame}{Логарифмирование}

Четыре модели:

\begin{itemize}
\item
  \(y_i = \beta_1 + \beta_2 x_i + \varepsilon_i\)
\item
  \(\ln( y_i) = \beta_1 + \beta_2 \ln( x_i) + \varepsilon_i\)
\item
  \(\ln( y_i) = \beta_1 + \beta_2 x_i + \varepsilon_i\)
\item
  \(y_i = \beta_1 + \beta_2 \ln( x_i) + \varepsilon_i\)
\end{itemize}

\end{frame}

\begin{frame}{Вывод интерпретации {[}у доски{]}}

Идея получения интерпретации логарифмических моделей:

\(d \ln x= \frac{dx}{x}\) --- изменение \(x\) в долях

\end{frame}

\begin{frame}{Две популярные версии}

\begin{itemize}
\item
  \(y_i = \beta_1 + \beta_2 x_i + \varepsilon_i\). С ростом \(x\) на
  единицу \(y\) растет на \(\beta_2\) единиц.
\item
  \(\ln( y_i) = \beta_1 + \beta_2 \ln( x_i) + \varepsilon_i\). С ростом
  \(x\) на один процент \(y\) растет на \(\beta_2\) процентов.
\end{itemize}

\end{frame}

\begin{frame}{Полулогарифмические модели}

\begin{itemize}
\item
  \(\ln( y_i) = \beta_1 + \beta_2 x_i + \varepsilon_i\). С ростом \(x\)
  на единицу \(y\) растет на \(100\beta_2\) процентов.
\item
  \(y_i = \beta_1 + \beta_2 \ln( x_i) + \varepsilon_i\). С ростом \(x\)
  на один процент \(y\) растет на \(0.01\beta_2\) единиц.
\end{itemize}

\end{frame}

\begin{frame}{Дамми-переменные}

\begin{itemize}
\item
  Объясняющая переменная, принимающая значение 0 или 1, называется
  дамми-переменной (dummy variable)
\item
  Например, пол респондента в опросе, переменная \(male_i\), равная 1
  для мужчин и 0 --- для женщин.
\end{itemize}

\end{frame}

\begin{frame}{Дамми-переменные и разные зависимости на подвыборках}

Пример 1. Базовая модель.

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

Зарплата мужчин и женщин в среднем одинаковая при равном опыте и
образовании

\end{frame}

\begin{frame}{Пример 2.}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \varepsilon_i\)

Для мужчин:
\(wage_i = (\beta_1+\beta_4) + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

Для женщин:
\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

\end{frame}

\begin{frame}{Пример 3.}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \beta_5 male_i exper_i + \varepsilon_i\)

Для мужчин:
\(wage_i = (\beta_1+\beta_4) + (\beta_2+\beta_5) exper_i + \beta_3 educ_i + + \varepsilon_i\)

Для женщин:
\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

\end{frame}

\begin{frame}{Пример 4.}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \beta_5 male_i educ_i + \varepsilon_i\)

Для мужчин:
\(wage_i = (\beta_1+\beta_4) + \beta_2 exper_i + (\beta_3 + \beta_5) educ_i + \varepsilon_i\)

Для женщин:
\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

\end{frame}

\begin{frame}{Пример 5.}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \beta_5 male_i educ_i + \beta_6 male_i exper_i + \varepsilon_i\)

Для мужчин:
\(wage_i = (\beta_1+\beta_4) + (\beta_2 + \beta_6) exper_i + (\beta_3 + \beta_5) educ_i + \varepsilon_i\)

Для женщин:
\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

\end{frame}

\begin{frame}{Факторная переменная принимает несколько значений}

\(season_i \in \{\text{ зима }, \text{ весна }, \text{ лето }, \text{ осень } \}\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Выбираем базовое значение факторной переменной: зима.
\item
  Вводим 3 (четыре сезона минус один базовый) дамми-переменных:
\end{enumerate}

\(vesna_i\), \(leto_i\), \(osen_i\)

\end{frame}

\begin{frame}{Вводим дамми-переменные}

\begin{tabular}{ccccc}
\hline 
Наблюдение & Сезон & $vesna_i$ & $leto_i$ & $osen_i$  \\ 
\hline 
1 & Зима & 0 & 0 & 0 \\ 
2 & Весна & 1 & 0 & 0 \\ 
3 & Лето & 0 & 1 & 0 \\ 
4 & Осень & 0 & 0 & 1 \\ 
5 & Зима & 0 & 0 & 0 \\ 
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\ 
\hline 
\end{tabular}

\end{frame}

\begin{frame}{Модели для подвыборок на примере}

\(icecream_i=\beta_1 + \beta_2 price_i + \beta_3 vesna_i + \beta_4 leto_i + \beta_5 osen_i + \varepsilon_i\)

Зима: \(icecream_i=\beta_1 + \beta_2 price_i + \varepsilon_i\)

Весна:
\(icecream_i=(\beta_1 + \beta_3) + \beta_2 price_i + \varepsilon_i\)

Лето:
\(icecream_i=(\beta_1 + \beta_4) + \beta_2 price_i + \varepsilon_i\)

Осень:
\(icecream_i=(\beta_1 + \beta_5) + \beta_2 price_i + \varepsilon_i\)

\end{frame}

\begin{frame}{Частая ошибка!}

Включить дамми-переменные на все значения факторной перенной и константу
в регрессию. Благородные доны и дуэньи так не поступают!

Пример с ошибкой (!).

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 male_i + \beta_4 female_i +\varepsilon_i\)

Выполнено соотношение \(1 = male_i + female_i\).

\end{frame}

\begin{frame}{частая ошибка --- нарушение предпосылки}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  С вероятностью 1 среди регрессоров нет линейно зависимых
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Синонимы в матричном виде: \(rank(X)=k\) или \(det(X'X)\neq 0\) или
  \((X'X)^{-1}\) существует
\end{itemize}

Регрессоры линейно зависимы. Не существует единственных оценок МНК.

\end{frame}

\begin{frame}{Проверка гипотез о нескольких ограничениях сразу}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \beta_5 male_i educ_i + \varepsilon_i\)

Для мужчин:
\(wage_i = (\beta_1+\beta_4) + \beta_2 exper_i + (\beta_3 + \beta_5) educ_i + \varepsilon_i\)

Для женщин:
\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

\(H_0: \begin{cases} \beta_4 = 0 \\ \beta_5 = 0 \end{cases}\)

\(H_a:\) хотя бы один коэффициент (\(\beta_4\) или \(\beta_5\)) отличен
от нуля

\end{frame}

\begin{frame}{Проверка гипотезы}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Оценить неограниченную модель (unrestricted, ur)
\end{enumerate}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \beta_4 male_i + \beta_5 male_i educ_i + \varepsilon_i\)

Посчитать \(RSS_{UR}\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Оценить ограниченную модель (restricted, r)
\end{enumerate}

\(wage_i = \beta_1 + \beta_2 exper_i + \beta_3 educ_i + \varepsilon_i\)

Посчитать \(RSS_{R}\)

\end{frame}

\begin{frame}{Два подхода:}

3.1. Асимптотически:

\[
\chi^2=\frac{RSS_R-RSS_{UR}}{RSS_{UR}/(n-k_{UR})} \to \chi^2_r
\]

3.2. При нормальности ошибок, \(\varepsilon_i |X \sim N(0,\sigma^2)\)

\[
F=\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k_{UR})} \sim F_{r, n-k_{UR}}
\]

\(r\) --- количество ограничений в \(H_0\)

\end{frame}

\begin{frame}{Вывод:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Если \(F_{obs}>F_{cr}\) или \(\chi^2_{obs}>\chi^2_{cr}\), то \(H_0\)
  отвергается
\end{enumerate}

\end{frame}

\begin{frame}[fragile]{Пример {[}у доски{]}}

\begin{verbatim}
## Error in file(file, "rt"): cannot open the connection
\end{verbatim}

\begin{verbatim}
## Error in is.data.frame(data): object 'h' not found
\end{verbatim}

\begin{verbatim}
## Error in is.data.frame(data): object 'h' not found
\end{verbatim}

Проверьте гипотезу о двух ограничениях. RSS для двух моделей:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_1 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data=}\NormalTok{h, }\KeywordTok{log}\NormalTok{(price)~}\KeywordTok{log}\NormalTok{(totsp)+}\KeywordTok{log}\NormalTok{(livesp)+}
\StringTok{                }\KeywordTok{log}\NormalTok{(kitsp)+brick+metrdist+walk)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in is.data.frame(data): object 'h' not found
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{data=}\NormalTok{h, }\KeywordTok{log}\NormalTok{(price)~}\KeywordTok{log}\NormalTok{(totsp)+}\KeywordTok{log}\NormalTok{(livesp)+}
\StringTok{                }\KeywordTok{log}\NormalTok{(kitsp)+brick)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in is.data.frame(data): object 'h' not found
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{deviance}\NormalTok{(model_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in deviance(model_1): object 'model_1' not found
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{deviance}\NormalTok{(model_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in deviance(model_2): object 'model_2' not found
\end{verbatim}

\end{frame}

\begin{frame}{Примечание.}

RSS ограниченной модели всегда больше:

\begin{itemize}
\item
  \(RSS_{UR} = \min_{\hat{\beta}_1, \hat{\beta}_2, \ldots} RSS\)
\item
  \(RSS_{R} = \min_{\hat{\beta}_1, \hat{\beta}_2, \ldots, \hat{\beta}_4=0} RSS\)
\end{itemize}

TSS в моделях равны, т.к. \(TSS=\sum ( y_i -\bar{y})^2\)

Следовательно, \(ESS_{UR}>ESS_R\) и \(R^2_{UR}>R^2_R\).

\end{frame}

\begin{frame}{Самый простой случай}

Модель \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)

Гипотеза \(H_0\): все наши регрессоры абсолютно бесполезны

\(H_0: \begin{cases} \beta_2 =0 \\ \beta_3 = 0 \\ ... \end{cases}\)

Всего \((k-1)\) ограничение.

Гипотеза о незначимости регрессии.

\end{frame}

\begin{frame}{Доказательство формулы статистики для гипотезы о
незначимости регрессии {[}у доски{]}}

Для гипотезы:

\(H_0: \begin{cases} \beta_2 =0 \\ \beta_3 = 0 \\ ... \\ \beta_k= 0 \end{cases}\)

Статистика приобретает вид:

\[
F=\frac{ESS/(k-1)}{RSS/(n-k)} \sim F_{k-1, n-k}
\]

Идея доказательства: ограниченной моделью будет модель
\(y_i=\beta_1 + \e_i\).

В ограниченной модели \(\hb_1=\bar{y}\) и \(RSS_R=TSS_R\), а
\(ESS_R=0\).

\end{frame}

\begin{frame}{Проверка гипотезы о незначимости регрессии}

Модель \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)

\(H_0: \begin{cases} \beta_2 =0 \\ \beta_3 = 0 \end{cases}\)

\[
F=\frac{ESS/(k-1)}{RSS/(n-k)} \sim F_{k-1, n-k}
\]

\end{frame}

\begin{frame}{Пример проверки гипотезы о незначимости регресии {[}у
доски{]}}

Для регрессии \[
\widehat{wage}_i=-2.5+0.6 school_i + 0.157 exper_i
\]

Проверьте гипотезу о незначимости регрессии в целом.

\(R^2=0.09\), \(n=3294\).

\end{frame}

\begin{frame}{Снова БСХС --- предпосылки}

Если:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Истинная зависимость имеет вид
  \(y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i+\varepsilon_i\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(y=X\beta + \varepsilon\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  С помощью МНК оценивается регрессия \(y\) на константу, \(x_i\),
  \(z_i\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(\hat{\beta}=(X'X)^{-1}X'y\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Наблюдений больше, чем оцениваемых коэффициентов \(\beta\): \(n>k\)
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предположения на \(\varepsilon_i\):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Строгая экзогенность:
  \(E(\varepsilon_i | \text{ все регрессоры } )=0\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(E(\varepsilon_i | X)=0\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Условная гомоскедастичность:
  \(E(\varepsilon_i^2 | \text{ все регрессоры })=\sigma^2\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  В матричном виде: \(E(\varepsilon_i^2 | X)=\sigma^2\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  \(Cov(\varepsilon_i,\varepsilon_j | X)=0\) при \(i \neq j\)
\end{enumerate}

\end{frame}

\begin{frame}{БСХС --- предпосылки на регрессоры}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  векторы отдельных наблюдений \((x_i,z_i,y_i)\) --- независимы и
  одинаково распределены
\item
  с вероятностью 1 среди регрессоров нет линейно зависимых
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Синонимы в матричном виде: \(rank(X)=k\) или \(det(X'X)\neq 0\) или
  \((X'X)^{-1}\) существует
\end{itemize}

\end{frame}

\begin{frame}{БСХС --- асимптотические свойства (плюс новое)}

При \(n\to \infty\):

\begin{itemize}
\tightlist
\item
  \(\hat{\beta}_j \to \beta_j\) по вероятности
\item
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)\) по
  распределению
\item
  \(\hat{\sigma}^2 \to \sigma^2\) по вероятности
\item
  новое:
  \(\chi^2=\frac{RSS_R-RSS_{UR}}{RSS_{UR}/(n-k_{UR})} \to \chi^2_r\)
\end{itemize}

\(\hat{\sigma}^2=\frac{RSS}{n-k}\)

\end{frame}

\begin{frame}{БСХС --- при нормальности}

Если дополнительно известно, что \(\varepsilon_i \sim N(0, \sigma^2)\):

\begin{itemize}
\tightlist
\item
  Оценки эффективны среди несмещенных
\item
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}|X \sim t_{n-k}\),
  \(\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)}\sim t_{n-k}\)
\item
  \(RSS/\sigma^2 |X \sim \chi^2_{n-k}\),
  \(RSS/\sigma^2 \sim \chi^2_{n-k}\)
\item
  новое:
  \(F=\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k_{UR})} |X \sim F_{r, n-k_{UR}}\)
\end{itemize}

\end{frame}

\begin{frame}{Лишние переменные}

\begin{itemize}
\item
  Истина: \(y_i = \beta_1 + \beta_2 x_i +\varepsilon_i\)
\item
  Оценена регрессия:
  \(\hat{y}_i=\hat{\beta}_1 + \hat{\beta}_2 x_i + \hat{\beta}_3 z_i\)
\item
  Потеряна: эффективность
\end{itemize}

\end{frame}

\begin{frame}{Пропущенные переменные}

\begin{itemize}
\item
  Истина: \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i +\varepsilon_i\)
\item
  Оценена регрессия: \(\hat{y}_i=\hat{\beta}_1 + \hat{\beta}_2 x_i\)
\item
  Всё плохо!
\end{itemize}

\end{frame}

\begin{frame}{Мораль:}

\begin{itemize}
\item
  Если в теории предполагается зависимость от переменной \(z\), то её
  лучше включить в модель, даже если она не значима.
\item
  Если переменные значимы, то их лучше оставить в модели, даже если
  теория говорит, что зависимости от них быть не должно.
\end{itemize}

\end{frame}

\begin{frame}{Увидеть то, чего нет}

\begin{itemize}
\item
  Как проверить не пропущены ли переменные, которых нет?
\item
  RESET-тест Рамсея
\end{itemize}

\(H_0: y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)

\(H_a:\) Есть неизвестные нам пропущенные регрессоры

\end{frame}

\begin{frame}{Алгоритм теста Рамсея:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Оценить модель:
  \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i\)
\end{enumerate}

Получить прогнозы \(\hat{y}_i\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Оценить модель:
  \(y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \gamma_1 \hat{y}^2_i + \gamma_2 \hat{y}^3_i + \ldots + \gamma_p \hat{y}_i^{p+1} + \varepsilon_i\)
\item
  Посчитать \(F\)-статистику проверяющую гипотезу о равенстве всех
  \(\gamma_i\) нулю.
\end{enumerate}

Рамсей: при верной \(H_0\) и нормальности остатков \(F\sim F_{p,n-k-p}\)

\end{frame}

\begin{frame}{Пример теста Рамсея {[}у доски{]}}

Для регрессии \[
\widehat{wage}_i=-2.5+0.6 school_i + 0.157 exper_i
\]

Проверьте тест Рамсея, если:

\begin{itemize}
\item
  \(R^2=0.091\) (в основной регрессии),
\item
  \(R^2_{aux}=0.095\) (во вспомогательной регрессии Рамсея),
\item
  \(n=3294\).
\end{itemize}

\end{frame}

\begin{frame}{Простые показатели качества}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(R^2\). Растет с добавлением регрессоров, \(R^2_{ur}>R^2_r\)
\item
  \(R^2_{adj}=1-\frac{RSS/(n-k)}{TSS/(n-1)}=1-\frac{\hat{\sigma}^2}{TSS/(n-1)}\)
\end{enumerate}

Чем больше \(R^2_{adj}\) тем меньше \(\hat{\sigma}^2\).

\end{frame}

\begin{frame}{Информационные критерии}

Модель плохая если:

\begin{itemize}
\item
  плохо предсказывает (\(RSS\) большой)
\item
  сложная (много коэффицентов, большое \(k\))
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Информационные критерии (размер штрафа):
\end{enumerate}

\begin{itemize}
\item
  Акаике \(AIC=n \ln (RSS/n) + 2k\)
\item
  Шварца \(BIC=n \ln (RSS/n) + \ln(n) k\)
\end{itemize}

\end{frame}

\begin{frame}{Мораль}

В этой лекции:

\begin{itemize}
\item
  Прогнозирование
\item
  Гипотезы о нескольких ограничениях
\item
  RESET-тест Рамсея
\end{itemize}

Далее: о неприятностях :)

\begin{block}{Источники мудрости:}

\begin{itemize}
\item
  Артамонов Н.В., Введение в эконометрику: главы 2.4, 2.5, 3.2
\item
  Борзых Д.А., Демешев Б.Б. Эконометрика в задачах и упражнениях: глава
  3
\item
  Катышев П.К., Пересецкий А. А. Эконометрика. Начальный курс: главы 3.5
\item
  Себер Дж., Линейный регрессионный анализ: главы 4.1, 5.1, 5.2, 5.3
\end{itemize}

\end{block}

\end{frame}

\end{document}
