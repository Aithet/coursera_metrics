---
title: "Автокорреляция"
lang: russian
header-includes: 
  - \author[Эконометрика. Лекция 6]{Эконометрика. Лекция 6}
  - \newcommand{\e}{\varepsilon}
output:
  beamer_presentation:
    keep_tex: yes
    theme: Madrid
    colortheme: whale
  ioslides_presentation: default
---



# Автокорреляция! 

Для проверки гипотез мы предполагали условную некоррелированность ошибок:

$E(\e_i \e_j | X)=0$ при $i\neq j$

Что произойдет если эта предпосылка будет нарушена?


# Когда логично ожидать автокорреляцию?

* <<близость>> наблюдений во времени или в пространстве

* наличие ненаблюдаемого фактора, действующего на <<соседние>> наблюдения

# Автокорреляцию подробно изучают!

* анализ временных рядов

* пространственная эконометрика

# Автокорреляция бывает небезобидной

* может привести к несостоятельности оценок $\hat{\beta}$

# Чудо-доска

$\e_1=\e_2=\ldots=\e_n=\pm 1$

отметим, что $E(\e_1\e_2 | x)=1$

# Автокорреляция может иметь очень сложную богатую структуру

* AR, MA, ARMA, ARIMA, VAR, VMA, VARMA, VECM, ARCH, GARCH, EGARCH, FIGARCH, TARCH, AVARCH, ZARCH, CCC, DCC, BEKK, VEC, DLM, ... 

(тут можно страшными сокращениями заполнить весь экран)

# Мы рассмотрим автокорреляцию порядка $p$

* Начнем с автокорреляции первого порядка, $p=1$

 $\e_{t}=\rho \e_{t-1}+u_t$

# Предпосылки 

* $\e_{t}=\rho \e_{t-1}+u_t$

* $u_t$ --- независимы между собой, 

* $u_t$ независимы от регрессоров

* $u_t$ одинаково распределены

* $E(u_t)=0$, $Var(u_t)=\sigma^2_u$


# упражнение у чудо-доски

Как выглядит $Corr(\e_{t}, \e_{t-k})$ при автокорреляции первого порядка?

# Автокорреляция порядка $p$:

$\e_{t}=\phi_1 \e_{t-1}+\phi_2 \e_{t-2} +\ldots + \phi_p \e_{t-p}+u_t$

допускает более богатую структуру $Corr(\e_i, \e_j)$

Как и в случае автокорреляции первого порядка, 
\[
\lim_{k\to\infty} Corr(\e_t, \e_{t-k})=0
\]

# условная автокорреляция и другие предпосылки

* автоматом нарушена предпосылка о незавимости наблюдений $(x_{i.}, y_i)$  

* во временных рядах обычно нарушена предпосылка $E(\e_t | X)=0$

например, использование $y_{t-1}$ в качестве регрессора нарушает $E(\e_t | X)=0$

(сказать про остальные предпосылки, и более слабые варианты)

# Мы используем прежние формулы:

* Для оценок коэффициентов:
$\hat{\beta}=(X'X)^{-1}X'y$

* Для оценки ковариационной матрицы оценок коэффициентов,
$\widehat{Var}(\hat{\beta}|X)=\frac{RSS}{n-k}(X'X)^{-1}$

* В частности, $\widehat{Var}(\hat{\beta}_j|X)=\frac{\hat{\sigma}^2}{RSS_j}$
и $se(\hat{\beta}_j)=\sqrt{\widehat{Var}(\hat{\beta}_j|X)}$


# Три группы свойств:

* конечная выборка без предположения о нормальности $\e$

* конечная выборка с предположением о нормальности $\e$

* асимптотические свойства (без предположения о нормальности  $\e$)

Что происходит в каждом случае?

# Конечная выборка без предположения о нормальности $\e$

* Линейность по $y$

* Условная несмещенность, $E(\hat{\beta}|X)=\beta$

* (---) Оценки неэффективны

#  Конечная выборка с предположением о нормальности $\e$

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} | X \sim t_{n-k}$

* (---) $\frac{RSS}{\sigma^2} |X \sim \chi^2_{n-k}$

* (---) $\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k)} \sim F_{r,n-k}$

#  Асимптотические свойства:

*  $\hat{\beta} \to \beta$

* $\frac{RSS}{n-k} \to \sigma^2$ 

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)$

* (---) $\frac{RSS_R-RSS_{UR}}{RSS_{UR}/(n-k)} \to \chi^2_r$

# Мораль:

* Сами $\hat{\beta}$ можно интерпретировать и использовать

* Стандартные ошибки $se(\hat{\beta}_j)$ несостоятельны

* Не можем строить доверительные интервалы для $\beta_j$ и проверять гипотезы

# Что делать?

* Исправить стандартные ошибки! 

* Другая формула для оценки $\widehat{Var}_{HAC}(\hat{\beta}|X)$

* Следовательно, другие $se_{HAC}(\hat{\beta}_j)$

# Робастная (устойчивая) к условной гетероскедастичности и автокорреляции оценка ковариационной матрицы

* Вместо $\widehat{Var}(\hat{\beta}|X)=\frac{RSS}{n-k}(X'X)^{-1}$ 

использовать 
\[
\widehat{Var}_{HAC}(\hat{\beta}|X)=(X'X)^{-1}\hat{\Phi}(X'X)^{-1}
\]

* Нью-Вест (Newey-West), 1987  (Существует много вариантов)

\[
\hat{\Phi} = \sum_{j=-k}^k \frac{k-|j|}{k} \left(  \sum_t \hat{\e}_t\hat{\e}_{t+j} x_{t\,\cdot}'x_{t+j\,\cdot} \right)
\]

# Суть корректировки:

Мы меняем $se(\hat{\beta}_j)$ на $se_{HAC}(\hat{\beta}_j)$

Какие проблемы решены?

* $\frac{\hat{\beta}_j-\beta_j}{se_{HAC}(\hat{\beta}_j)} \to N(0,1)$ (УРА!)

# Какие проблемы не решены?

(---) оценки $\hat{\beta}$ не меняются и остаются неэффективными


даже при предположении о нормальности $\e$:

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} | X \sim t_{n-k}$

* (---) $\frac{RSS}{\sigma^2} |X \sim \chi^2_{n-k}$

* (---) $\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k)} \sim F_{r,n-k}$

# С практической точки зрения:

* Новая формула для $\widehat{Var}_{HAC}(\hat{\beta}|X)$, и, следовательно, для  $se_{HAC}(\hat{\beta}_j)$

* ковариационная матрица в R:
```{r, eval=FALSE}
model <- lm(y~x, data=data)
vcovHAC(model)
```

* С ней жизнь прекрасна!

$\frac{\hat{\beta}_j-\beta_j}{se_{HAC}(\hat{\beta}_j)} \to N(0,1)$

# Когда следует использовать 

* Когда мы подозреваем наличие автокорреляции и не хотим заниматься её моделированием

# Обнаружение автокорреляции

* Оцениваем интересующую нас модель с помощью МНК

* Строим график остатков в осях $\hat{\e}_{t-1}$, $\hat{\e}_{t}$

/здесь пришлю три графика/

# Формальные тесты на автокорреляцию

* тест Дарбина-Уотсона (Durbin-Watson)

* тест Бройша-Годфри (Breusch-Godfrey)


# Тест Дарбина-Уотсона предпосылки:

* Автокорреляция первого порядка в остатках

\[
\e_t=\rho \e_{t-1} + u_t
\]

* нормальность ошибок $\e$

* сильная экзогенность, $E(\e_t | X)=0$

* $H_0$ об отсутствии автокорреляции, $\rho=0$

# процедура теста Дарбина-Уотсона

* Шаг 1. Оценить основную регрессию, получить $\hat{\e}_i$

* Шаг 2. Посчитать статистику 
$$DW=\frac{\sum_{i=2}^n(\hat{\e}_i-\hat{\e}_{i-1})^2}{\sum_{i=1}^n \hat{\e}_i^2}$$

# Распределение статистики $DW$

* $H_0$ об отсутствии автокорреляции, $\rho=0$

* Точный закон распределения сложным образом зависит от $X$

* Если $\hat{\rho}$ --- выборочная корреляция остатков, то $DW=2(1-\hat{\rho})$

# Качественные выводы по статистике $DW$

$DW=2(1-\hat{\rho})$, поэтому $0<DW<4$

* $DW\approx 0$ означает положительную автокорреляцию $\hat{\rho}\approx 1$

* $DW\approx 2$ означает отсутствие автокорреляции $\hat{\rho}\approx 0$

* $DW\approx 4$ означает отрицательную автокорреляцию $\hat{\rho}\approx -1$

# иллюстрация (рисунок прилагается: график про Дарбина-Уотсона)

теховские надписи для графиков:

$H_0$ не отвергается
$H_0$ отвергается
$DW_{cr}$
$H_0$: $\rho=0$

# С практической точки зрения: 

* `R` рассчитывает точные P-значения для теста $DW$

* существуют таблицы  диапазонов критических значений



# Тест Бройша-Годфри (Breusch-Godfrey)

* для тестирования автокорреляции порядка $p$ в ошибках
\[
\e_t=\phi_1 \e_{t-1} + \ldots + \phi_p \e_{t-p} + u_t
\]

* не требуется нормальность остатков 

* верен при ряде нарушений предпосылки $E(\e_t | X)=0$

* асимптотический

$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

# Процедура теста Бройша-Годфри

* Шаг 1. Оцениваем исходную модель, получаем остатки $\hat{\e}_t$

* Шаг 2. Строим вспомогательную регрессию  $\hat{\e}_t$ на исходные регрессоры, $\hat{\e}_{t-1}$, $\hat{\e}_{t-2}$, ..., $\hat{\e}_{t-p}$, находим $R^2_{aux}$

* Шаг 3. Считаем статистику $BG=(n-p)R^2_{aux}$

# Тест Бройша-Годфри продолжение

* При верной $H_0$ об отсутствии автокорреляции

$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

$BG=(n-p)R^2_{aux} \sim \chi^2_p$

Здесь график распределения BG (рисунок прилагается)
Подписи на графике:

$H_0$ не отвергается
$H_0$ отвергается
$\chi^2_{cr}$
$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

 
# Тест Бройша-Годфри требует меньше предпосылок


# Вставка с чудо-доской

Тест Дарбина-Уотсона и Бройша-Годфри (уже снят)

здесь в задаче было дано $DW$, надо было найти $\hat{\rho}$ и провести тест Бройша-Годфри

# Мораль

* Мы рассмотрели ситуацию нарушения предпосылки условной некоррелированности ошибок модели

* Нарушена во временных рядах и пространственных данных
 
* В простейшем случае достаточно использовать специальные стандартные ошибки $se_{HAC}$ 
 
* Большое количество специальных моделей 







 

 
