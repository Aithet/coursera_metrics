\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm,landscape]{geometry}
\begin{document}


{\Huge

\begin{enumerate}

\item Автокорреляция! 

Для проверки гипотез мы предполагали условную некоррелированность ошибок:

$ E(\varepsilon_i \varepsilon_j | X)=0 $ при $i\neq j$

Что произойдет если эта предпосылка будет нарушена?


\item Когда логично ожидать автокорреляцию?

* <<близость>> наблюдений во времени или в пространстве

* наличие ненаблюдаемого фактора, действующего на <<соседние>> наблюдения

\item Автокорреляцию подробно изучают!

* анализ временных рядов

* пространственная эконометрика

\item Автокорреляция бывает небезобидной

* может привести к несостоятельности оценок $\hat{\beta}$

\item Чудо-доска

$\varepsilon_1=\varepsilon_2=\ldots=\varepsilon_n=\pm 1$

отметим, что $E(\varepsilon_1\varepsilon_2 | x)=1$

\item Автокорреляция может иметь очень сложную богатую структуру

* AR, MA, ARMA, ARIMA, VAR, VMA, VARMA, VECM, ARCH, GARCH, EGARCH, FIGARCH, TARCH, AVARCH, ZARCH, CCC, DCC, BEKK, VEC, DLM, ... 

(тут можно страшными сокращениями заполнить весь экран)

\newpage
\item Мы рассмотрим автокорреляцию порядка $p$

$p=1$: автокорреляция первого порядка

$\varepsilon_{t}=\rho \varepsilon_{t-1}+u_t$

$u_t$ --- независимы между собой, 

--- независимы от регрессоров

- одинаково распределены

-$E(u_t)=0$, $Var(u_t)=\sigma^2_u$


\item упражнение у чудо-доски

Как выглядит $Corr(\varepsilon_{t}, \varepsilon_{t-k})$ при автокорреляции первого порядка?

\newpage
\item Автокорреляция порядка $p$:

$\varepsilon_{t}=\phi_1 \varepsilon_{t-1}+\phi_2 \varepsilon_{t-2} +\ldots + \phi_p \varepsilon_{t-p}u_t$

допускает более богатую структуру $Corr(\varepsilon_i, \varepsilon_j)$

Как и в случае автокорреляции первого порядка, 
\[
\lim_{k\to\infty} Corr(\varepsilon_t, \varepsilon_{t-k})=0
\]

\item условная автокорреляция и другие предпосылки

* автоматом нарушена предпосылки о незавимости наблюдений $(x_{i.}, y_i)$  

* во временных рядах обычно нарушена предпосылка $E(\varepsilon_t | X)=0$

например, использование $y_{t-1}$ в качестве регрессора нарушает $E(\varepsilon_t | X)=0$

(сказать про остальные предпосылки, и более слабые варианты)

\newpage
\item  Мы используем прежние формулы:

Для оценок коэффициентов:
$\hat{\beta}=(X'X)^{-1}X'y$

Для оценки ковариационной матрицы оценок коэффициентов,
$\widehat{Var}(\hat{\beta})=\frac{RSS}{n-k}(X'X)^{-1}$

В частности, $\widehat{Var}(\hat{\beta}_j)=\frac{\hat{\sigma}^2}{RSS_j}$
и $se(\hat{\beta}_j)=\sqrt{\widehat{Var}(\hat{\beta}_j)}$


\item Три группы свойств:

- конечная выборка без предположения о нормальности $\varepsilon$

- конечная выборка с предположением о нормальности $\varepsilon$

- асимптотические свойства (без предположения о нормальности  $\varepsilon$)

Что происходит в каждом случае?
\newpage
\item Конечная выборка без предположения о нормальности $\varepsilon$

* Линейность по $y$

* Условная несмещенность, $E(\hat{\beta}|X)=\beta$

* (---) Оценки неэффективны

\item  Конечная выборка с предположением о нормальности $\varepsilon$

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} | X \sim t_{n-k}$

* (---) $\frac{RSS}{\sigma^2} |X \sim \chi^2_{n-k}$

* (---) $\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k)} \sim F_{r,n-k}$

\newpage
\item  Асимптотические свойства:

*  $\hat{\beta} \to \beta $

* $\frac{RSS}{n-k} \to \sigma^2 $ 

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \to N(0,1)$

* (---) $\frac{RSS_R-RSS_{UR}}{RSS_{UR}/(n-k)} \to \chi^2_r$

\item Мораль:

* Сами $\hat{\beta}$ можно интерпретировать и использовать

* Стандартные ошибки $se(\hat{\beta}_j)$ несостоятельны

* Не можем строить доверительные интервалы для $\beta_j$ и проверять гипотезы

\newpage
\item Что делать?

* Исправить стандартные ошибки! 

* Другая формула для оценки $\widehat{Var}_{HAC}(\hat{\beta})$

* Следовательно, другие $se_{HAC}(\hat{\beta}_j)$

\item Робастная (устойчивая) к условной гетероскедастичности и автокорреляции оценка ковариационной матрицы

* Вместо $\widehat{Var}(\hat{\beta})=\frac{RSS}{n-k}(X'X)^{-1}$ 

использовать 
\[
\widehat{Var}_{HAC}(\hat{\beta})=(X'X)^{-1}\hat{\Phi}(X'X)^{-1}
\]

* Нью-Вест (Newey-West), 1987  (Существует много вариантов)

\[
\hat{\Phi} = \sum_{j=-k}^k \frac{k-|j|}{k} \left(  \sum_t \hat{\varepsilon}_t\hat{\varepsilon}_{t+j} x_{t\,\cdot}'x_{t+j\,\cdot} \right)
\]

\newpage
\item  Суть корректировки:

Мы меняем $se(\hat{\beta}_j)$ на $se_{HAC}(\hat{\beta}_j)$

Какие проблемы решены?

* $\frac{\hat{\beta}_j-\beta_j}{se_{HAC}(\hat{\beta}_j)} \to N(0,1)$ (УРА!)

\item Какие проблемы не решены?

(---) оценки $\hat{\beta}$ не меняются и остаются неэффективными


даже при предположении о нормальности $\varepsilon$:

* (---) $\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} | X \sim t_{n-k}$

* (---) $\frac{RSS}{\sigma^2} |X \sim \chi^2_{n-k}$

* (---) $\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k)} \sim F_{r,n-k}$

\newpage
\item С практической точки зрения:

* Новая формула для $\widehat{Var}_{HAC}(\hat{\beta})$, и, следовательно, для  $se_{HAC}(\hat{\beta}_j)$

* ковариационная матрица в R:

\verb|model <- lm(y~x, data=data)|

\verb|vcovHAC(model)|

* С ней жизнь прекрасна!

$\frac{\hat{\beta}_j-\beta_j}{se_{HAC}(\hat{\beta}_j)} \to N(0,1)$

\item Когда следует использовать 

* Когда мы подозреваем наличие автокорреляции и не хотим заниматься её моделированием

\newpage

\item Обнаружение автокорреляции

* Оцениваем интересующую нас модель с помощью МНК

* Строим график остатков в осях $\hat{\varepsilon}_{t-1}$, $\hat{\varepsilon}_{t}$

/здесь пришлю три графика/

\item Формальные тесты на автокорреляцию

* тест Дарбина-Уотсона (Durbin-Watson)

* тест Бройша-Годфри (Breusch-Godfrey)


\newpage
\item Тест Дарбина-Уотсона предпосылки:

* Автокорреляция первого порядка в остатках

\[
\varepsilon_t=\rho \varepsilon_{t-1} + u_t
\]

* нормальность ошибок $\varepsilon$

* сильная экзогенность, $E(\varepsilon_t | X)=0$

* $H_0$ об отсутствии автокорреляции, $\rho=0$

\item процедура теста Дарбина-Уотсона

* Шаг 1. Оценить основную регрессию, получить $\hat{\varepsilon}_i$

* Шаг 2. Посчитать статистику 
$$DW=\frac{\sum_{i=2}^n(\hat{\varepsilon}_i-\hat{\varepsilon}_{i-1})^2}{\sum_{i=1}^n \hat{\varepsilon}_i^2}$$

\newpage
\item Распределение статистики $DW$

* $H_0$ об отсутствии автокорреляции, $\rho=0$

* Точный закон распределения сложным образом зависит от $X$

* Если $\hat{\rho}$ --- выборочная корреляция остатков, то $DW=2(1-\hat{\rho})$

\item Качественные выводы по статистике $DW$

$DW=2(1-\hat{\rho})$, поэтому $0<DW<4$

* $DW\approx 0$ означает положительную автокорреляцию $\hat{\rho}\approx 1$

* $DW\approx 2$ означает отсутствие автокорреляции $\hat{\rho}\approx 0$

* $DW\approx 4$ означает отрицательную автокорреляцию $\hat{\rho}\approx -1$

\item иллюстрация (рисунок прилагается: график про Дарбина-Уотсона)

теховские надписи для графиков:

$H_0$ не отвергается
$H_0$ отвергается
$DW_{cr}$
$H_0$: $\rho=0$

\newpage
\item С практической точки зрения: 

* \verb|R| рассчитывает точные P-значения для теста $DW$

* существуют таблицы  диапазонов критических значений



\item Тест Бройша-Годфри (Breusch-Godfrey)

* для тестирования автокорреляции порядка $p$ в ошибках
\[
\varepsilon_t=\phi_1 \varepsilon_{t-1} + \ldots + \phi_p \varepsilon_{t-p} + u_t
\]

* не требуется нормальность остатков 

* верен при ряде нарушений предпосылки $E(\varepsilon_t | X)=0$

* асимптотический

$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

\newpage
\item Процедура теста Бройша-Годфри

* Шаг 1. Оцениваем исходную модель, получаем остатки $\hat{\varepsilon}_t$

* Шаг 2. Строим вспомогательную регрессию  $\hat{\varepsilon}_t$ на исходные регрессоры, $\hat{\varepsilon}_{t-1}$, $\hat{\varepsilon}_{t-2}$, ..., $\hat{\varepsilon}_{t-p}$, находим $R^2_{aux}$

* Шаг 3. Считаем статистику $BG=(n-p)R^2_{aux}$

\newpage
\item Тест Бройша-Годфри продолжение

* При верной $H_0$ об отсутствии автокорреляции

$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

$BG=(n-p)R^2_{aux} \sim \chi^2_p$

Здесь график распределения BG (рисунок прилагается)
Подписи на графике:

$H_0$ не отвергается
$H_0$ отвергается
$\chi^2_{cr}$
$H_0$: $\phi_1=\phi_2=\ldots=\phi_p=0$

\newpage 
\item Тест Бройша-Годфри требует меньше предпосылок


\item Вставка с чудо-доской

Тест Дарбина-Уотсона и Бройша-Годфри (уже снят)

здесь в задаче было дано $DW$, надо было найти $\hat{\rho}$ и провести тест Бройша-Годфри

\item Мораль

* Мы рассмотрели ситуацию нарушения предпосылки условной некоррелированности ошибок модели

* Нарушена во временных рядах и пространственных данных
 
* В простейшем случае достаточно использовать специальные стандартные ошибки $se_{HAC}$ 
 
* Большое количество специальных моделей 







 

 




\end{enumerate}





} % скобка от хьюго
\end{document}